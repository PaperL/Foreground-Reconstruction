{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "from LUT.models_x import *\n",
    "from LUT import torchvision_x_functional as TF_x\n",
    "import torchvision.transforms.functional as TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = Path('demo/')\n",
    "lut_path = folder_path / 'lut.txt'\n",
    "img_path = folder_path / 'img.jpg'\n",
    "img_output_path = folder_path / 'output_lut.jpg'\n",
    "\n",
    "assert folder_path.is_dir and folder_path.exists\n",
    "assert lut_path.is_file and lut_path.exists\n",
    "assert img_path.is_file and img_path.exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qiutianyuan/workspace/Foreground-Reconstruction/LUT/models_x.py:153: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.LUT = nn.Parameter(torch.tensor(self.LUT))\n"
     ]
    }
   ],
   "source": [
    "# create LUT object on CUDA\n",
    "assert torch.cuda.is_available()\n",
    "Tensor = torch.cuda.FloatTensor\n",
    "trilinear_ = TrilinearInterpolation()\n",
    "\n",
    "LUT0 = Generator3DLUT_zero(dim=0)\n",
    "dim = 33\n",
    "\n",
    "file = open(str(lut_path), 'r')\n",
    "lines = file.readlines()\n",
    "buffer = np.zeros((3,dim,dim,dim), dtype=np.float32)\n",
    "\n",
    "for i in range(0,dim):\n",
    "    for j in range(0,dim):\n",
    "        for k in range(0,dim):\n",
    "            n = i * dim*dim + j * dim + k\n",
    "            x = lines[n].split()\n",
    "            buffer[0,i,j,k] = float(x[0])\n",
    "            buffer[1,i,j,k] = float(x[1])\n",
    "            buffer[2,i,j,k] = float(x[2])\n",
    "LUT0.LUT = nn.Parameter(torch.from_numpy(buffer).requires_grad_(True))\n",
    "LUT0 = LUT0.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LUT = LUT0.LUT\n",
    "\n",
    "# read image and transform to tensor\n",
    "img = Image.open(str(img_path))\n",
    "img = TF.to_tensor(img).type(Tensor)\n",
    "img = img.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate image\n",
    "_, result = trilinear_(LUT, img)\n",
    "\n",
    "# save image\n",
    "ndarr = result.squeeze().mul_(255).add_(0.5).clamp_(0, 255).permute(1, 2, 0).to('cpu', torch.uint8).numpy()\n",
    "im = Image.fromarray(ndarr)\n",
    "im.save(str(img_output_path), quality=95)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a2d0302cd44d3b13a55a0d683f2d47ccae8b5254f785ec9540a3d2eedfeb70dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
